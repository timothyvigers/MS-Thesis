---
title: "MS Thesis Work"
author: "Tim Vigers"
date: "6/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/timvigers/GitHub/MS-Thesis")
library(tidyverse)
library(patchwork)
library(DiagrammeR)
library(knitr)
library(bnlearn)
library(rjags)
```

```{r load datasets,echo=FALSE}
load("./data/networks/pair_data.Rdata")
load("./data/networks/all_dic.Rdata")
load("./data/networks/cits.Rdata")
source("./code/networks/network_structures.R")
```

# Bayesian networks with JAGS

## Network structures and models

### Structure

```{r echo=FALSE}
ndf <-
  create_node_df(
    n = 3,
    label = c("Methylation","Metabolite","T1D Status"),
    shape = c("oval", "oval","oval"),
    fixedsize=F
  )
edf <-
  create_edge_df(
    from = c(2,3,2),
    to   = c(3, 1, 1)
  )
graph <- 
  create_graph(
    nodes_df = ndf,
    edges_df = edf
  )
graph %>% render_graph()
```

### Models

$$
\text{T1D | Metabolite} \sim \text{Bern}(\text{logit}(\alpha_0 + \alpha_1*\text{Metabolite}))\\
\text{Methylation | Metabolite, T1D} \sim \text{N}(\delta+\gamma*\text{Metabolite}+\beta*\text{T1D},\sigma^2)\\
$$

### Priors

$$
\alpha_0 \sim \text{N}(0,0.0001)\\
\alpha_1 \sim \text{N}(0,0.0001)\\
\delta \sim \text{N}(0,0.0001)\\
\gamma \sim \text{N}(0,0.0001)\\
\beta \sim \text{N}(0,0.0001)\\
\sigma^2 = \frac{1}{\tau}\\
\tau \sim \text{Gamma}(0.0001,0.0001)
$$

## Model comparisons

### DIC distribution by network structure

```{r echo=FALSE}
# Format DIC data
t = as.data.frame(t(all_dics))
colnames(t) = paste0("struct",1:24)
t <- t %>% pivot_longer(struct1:struct24)
t$name = as.numeric(gsub("struct","",t$name))
# Plot
ggplot(t,aes(x=factor(name),y=value)) + 
  geom_boxplot() + 
  xlab("Structure number") + ylab("DIC") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90))
```

### DIC differences 

```{r echo=FALSE}
l = 
  lapply(colnames(all_dics), function(x){
    dics = all_dics[,x]
    pair = paste(cits[as.numeric(x),1],"-",cits[as.numeric(x),3])
    abs_diff_1_2 = diff(sort(dics)[1:2])
    abs_diff_2_3 = diff(sort(dics)[2:3])
    st = sd(dics)
    stand_diff_1_2 = abs_diff_1_2 / st
    stand_diff_2_3 = abs_diff_2_3 / st
    data.frame("Pair" = pair,
               "Abs.Diff.1.2" = abs_diff_1_2,"Std.Diff.1.2" = stand_diff_1_2,
               "Abs.Diff.2.3" = abs_diff_2_3,"Std.Diff.2.3" = stand_diff_2_3)
  })
dic_diff_table = do.call(rbind,l)
colnames(dic_diff_table) = 
  c("Pair","Abs. Diff. Best-Second","Std. Diff. Best-Second",
    "Abs. Diff. Second-Third","Std. Diff. Second-Third")
# Plot diff. distribution
diff_plot = dic_diff_table %>%
  pivot_longer(`Abs. Diff. Best-Second`:`Std. Diff. Second-Third`)
# Absolute
adp = 
  ggplot(diff_plot[diff_plot$name %in% c("Abs. Diff. Best-Second",
                                         "Abs. Diff. Second-Third"),]) + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Absolute DIC Difference")
# Densities
adp + 
  geom_density(aes(x = value,fill = name),alpha = 0.5) + 
  theme(legend.title = element_blank())
# Boxplots
adp + geom_boxplot(aes(x = name,y = value,fill = name)) + 
  theme(legend.position = "none") + xlab("")

# Standardized
adp = 
  ggplot(diff_plot[diff_plot$name %in% c("Abs. Diff. Best-Second",
                                         "Abs. Diff. Second-Third"),]) + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Absolute DIC Difference")

sdp = 
  ggplot(diff_plot[diff_plot$name %in% c("Std. Diff. Best-Second",
                                         "Std. Diff. Second-Third"),]) + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) + 
  theme_bw() + ggtitle("Standardized DIC Difference")
# Densities
sdp + 
  geom_density(aes(x = value,fill = name),alpha = 0.5) + 
  theme(legend.title = element_blank())
# Boxplots
sdp + geom_boxplot(aes(x = name,y = value,fill = name)) + 
  theme(legend.position = "none") + xlab("")
```

## Permutation tests

```{r echo=FALSE}
set.seed(1017)
# Permutation and MCMC parameters
nsim = 1000
n_adapt = 1000
iter = 10000
vars = c("alpha0","alpha","beta0","beta","gamma0","gamma")
# Data set for single pair of interest
metab = "bc_oxylipin8"
methyl = "cg08384146"
temp = pair_data[,c("T1Dgroup",methyl,metab)]
temp = temp[complete.cases(temp),]
temp$T1Dgroup = ifelse(temp$T1Dgroup == "T1D control",0,1)
N = nrow(temp)
# Permutations
perm_structs = 
  lapply(1:1000, function(x){
    perm = sample(nrow(temp))
    jags_data = 
      list(t1d=c(temp[perm,"T1Dgroup"]),methyl=c(temp[,methyl]),
           metab=c(temp[,metab]),
           N=N)
    dics = 
      suppressWarnings(lapply(paste0("struct",1:24), function(x){
        mod = 
          jags.model(paste0("./code/jags/",x,".jags"),quiet=T,
                     data = jags_data, n.adapt = n_adapt,n.chains = 2)
        dic = 
          dic.samples(mod,n.iter = iter,progress.bar="none")
        return(round(sum(dic$deviance) + sum(dic$penalty),1))
      }))
    which.min(dics)
  })
```

## Potential problems

### DIC

- "From Bayesian perspective, DIC is not theoretically justified since it measures the fit of the model when the parameters are fixed to the posterior expectation and is not therefore an unbiased estimate of the true generalization utility." (Piironen & Vehtari, 2017)

- "The numerical experiments show that the over-fitting in the selection may be a potential problem and hinder the model selection considerably. This is the case especially when the dataset is small (high variance in the utility estimates) and the number of models under comparison large (large number of variables). Especially vulnerable methods for this type of overfitting are CV, WAIC, DIC and other methods that rely on data reuse and have therefore relatively high variance in the utility estimates." (Piironen & Vehtari, 2017)

### Priors

Tim was wrong about gamma priors causing problems. This issue is specific to logistic models with random effects, where the prior is $b_i \sim N(0,\frac{1}{\lambda})$. The Piironen paper can be a little unclear, so maybe we need a better resource.

# References

- Piironen, J., & Vehtari, A. (2017). Comparison of Bayesian predictive methods for model selection. Statistics and Computing, 27(3), 711â€“735. https://doi.org/10.1007/s11222-016-9649-y